#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Exercise 1 Intro to Deep Learning: Nadav Eisen & Yonatan Miroshnik 
\end_layout

\begin_layout Part*
Practical Part:
\end_layout

\begin_layout Standard
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Standard
2.a.
 For every character in the 9 character peptide, I gave it a unique index,
 and from that I created a one-hot embedding for each character based on
 this unique index.
 Each 9 character length peptide is thus represented by a 180 bit long binary
 number of the consecutive one-hot embeddings of each character in the peptide.
\end_layout

\begin_layout Standard
2.b.
 The input dimension, as explained above, is a 180 bit long input.
 The offered neural network set up has a problem in our need to decide the
 size of the hidden layers and thus the number of weights.
\end_layout

\begin_layout Standard
2.c.
 
\end_layout

\begin_layout Standard
2.d.
 
\end_layout

\begin_layout Standard
2.e.
 We first go over the spike protein as given and divide it into all possible
 consecutive 9-peptides, we then pass it through the trained network, and
 return the most confidently positive peptides of the prediction, our resulting
 peptides are: 
\begin_inset Formula $ $
\end_inset

??
\end_layout

\begin_layout Part*
Question 1:
\end_layout

\begin_layout Standard
From basic linear algebra, we know that any linear functions 
\begin_inset Formula $f\in Hom\left(\mathbb{R}^{n},\mathbb{R}^{k}\right)$
\end_inset

, and 
\begin_inset Formula $g\in Hom\left(\mathbb{R}^{k},\mathbb{R}^{m}\right)$
\end_inset

 can be represented by matrices 
\begin_inset Formula $A\in M_{n\times k}\left(\mathbb{R}\right),B\in M_{k\times m}\left(\mathbb{R}\right)$
\end_inset

 appropriately, such that for all 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left(f\circ g\right)\left(x\right)=\left(A\circ B\right)\left(x\right)=\left(AB\right)\left(x\right)
\]

\end_inset


\end_layout

\begin_layout Standard
And the multiplication of matrices 
\begin_inset Formula $AB$
\end_inset

 is also a matrix, and therefore also a linear function 
\begin_inset Formula $\in Hom\left(\mathbb{R}^{n},\mathbb{R}^{m}\right)$
\end_inset

.
 For any affine 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{k}$
\end_inset

, 
\begin_inset Formula $g:\mathbb{R}^{k}\rightarrow\mathbb{R}^{m}$
\end_inset

 can be represented as 
\begin_inset Formula $f\left(x\right)=Ax+c$
\end_inset

, 
\begin_inset Formula $g\left(x\right)=Bx+d$
\end_inset

 where 
\begin_inset Formula $A\in M_{n\times k}\left(\mathbb{R}\right),B\in M_{k\times m}\left(\mathbb{R}\right)$
\end_inset

 and 
\begin_inset Formula $c\in\mathbb{R}^{n}$
\end_inset

, 
\begin_inset Formula $d\in\mathbb{R}^{k}$
\end_inset

, such that for any 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left(f\circ g\right)\left(x\right)=f\left(Bx+d\right)=A\left(Bx+d\right)+c=\left(AB\right)x+\left(Ad+c\right)
\]

\end_inset


\end_layout

\begin_layout Standard
From this form, since 
\begin_inset Formula $AB$
\end_inset

 is a matrix and 
\begin_inset Formula $Ad+c$
\end_inset

 is a vector in the image dimension, we can see that 
\begin_inset Formula $f\circ g$
\end_inset

 is an affine transformation
\end_layout

\begin_layout Part*
Question 2:
\end_layout

\begin_layout Section*
a)
\end_layout

\begin_layout Standard
To find the gradient descent step, we of course need to find the gradient.
 We know that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{df}{dx}=20\left(x-1\right),\frac{df}{dy}=\frac{1}{5}\left(y+1\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla f\begin{pmatrix}x\\
y
\end{pmatrix}=\frac{1}{5}\begin{pmatrix}100\left(x-1\right)\\
y+1
\end{pmatrix}=\begin{bmatrix}20\\
 & \frac{1}{5}
\end{bmatrix}\begin{pmatrix}x\\
y
\end{pmatrix}+\begin{pmatrix}-20\\
\frac{1}{5}
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore the gradient descent step from 
\begin_inset Formula $x^{k}$
\end_inset

 to 
\begin_inset Formula $x^{k+1}$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x^{k+1}=x^{k}-t\nabla f\left(x^{k}\right)=x^{k}-t\left(\begin{bmatrix}20\\
 & \frac{1}{5}
\end{bmatrix}x^{k}+\begin{pmatrix}-20\\
\frac{1}{5}
\end{pmatrix}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\begin{bmatrix}1-20t\\
 & 1-\frac{t}{5}
\end{bmatrix}x^{k}+\begin{pmatrix}20t\\
-\frac{t}{5}
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $t$
\end_inset

 is the step size, or the learning reate.
\end_layout

\begin_layout Section*
b)
\end_layout

\begin_layout Paragraph*

\series medium
We can see of course that the function reaches a minimum at 
\begin_inset Formula $x=1,y=-1$
\end_inset

, because it reaches 
\begin_inset Formula $f\begin{pmatrix}1\\
-1
\end{pmatrix}=0$
\end_inset

 and otherwise it is bounded from below by 0.
 
\end_layout

\begin_layout Paragraph*

\series medium
From the GD step we saw in the last section, we can see that every coordinate
 of 
\begin_inset Formula $x^{k}$
\end_inset

 is independent in every step, such that:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{1}^{k+1}=20t+x_{1}^{k}\left(1-20t\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{2}^{k+1}=-\frac{t}{5}+x_{2}^{k}\left(1-\frac{t}{5}\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
For any series of the form 
\begin_inset Formula $a_{0}=x$
\end_inset

 and 
\begin_inset Formula $a_{k+1}=a_{k}x+b$
\end_inset

, we can see that:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
a_{0}=x
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
a_{1}=ax+b
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
a_{2}=a^{2}x+ab+b
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
a_{3}=a^{3}x+a^{2}b+ab+b
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
We can therefore see recursively that 
\begin_inset Formula $a_{k}=a^{k}x+\frac{a^{k}-1}{a-1}b$
\end_inset

, as 
\begin_inset Formula $a_{0}=x+\frac{1-1}{a-1}b=x$
\end_inset

, and recursively:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
a_{k+1}=a\left(a^{k}x+\frac{a^{k}-1}{a-1}b\right)=a^{k+1}x+\sum_{i=1}^{k-1}a^{i}b+b
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
=a^{k+1}x+\sum_{i=0}^{k-1}a^{i}b=a^{k+1}x+\frac{a^{k+1}-1}{a-1}b
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
Therefore, we can see that:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{1}^{k}=\left(1-20t\right)^{k}x_{1}^{0}+\frac{1-\left(1-20t\right)^{k}}{20t}20t
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
=\left(1-20t\right)^{k}\left(x_{1}^{0}-1\right)+1
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
And:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{2}^{k}=\left(1-\frac{t}{5}\right)^{k}x_{2}^{0}+\frac{\left(1-\frac{t}{5}\right)^{k}-1}{-\frac{t}{5}}\left(-\frac{t}{5}\right)
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
=\left(1-\frac{t}{5}\right)^{k}\left(x_{2}^{0}+1\right)-1
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
Therefore, we can see that these series converge for all 
\begin_inset Formula $x^{0}$
\end_inset

 iff 
\begin_inset Formula $\left|1-20t\right|,\left|1-\frac{t}{5}\right|<1$
\end_inset

, and therefore 
\begin_inset Formula $t<10,\frac{1}{10}$
\end_inset

, or just 
\begin_inset Formula $t<\frac{1}{10}$
\end_inset

.
\end_layout

\begin_layout Paragraph*

\series medium
Therefore, the maximal learning rate is 
\begin_inset Formula $\frac{1}{10}$
\end_inset

, such that when 
\begin_inset Formula $t=\frac{1}{10}$
\end_inset

, 
\begin_inset Formula $x_{1}^{k}$
\end_inset

 bounces back and forth between 
\begin_inset Formula $x_{1}^{0}$
\end_inset

 and 
\begin_inset Formula $1+\left(1-x_{1}^{0}\right)$
\end_inset

, and when 
\begin_inset Formula $t>\frac{1}{10}$
\end_inset

 the series 
\begin_inset Formula $x_{1}^{k}$
\end_inset

 is unbounded.
\end_layout

\begin_layout Standard
—————————————————————————————————– NOTE: IS THE CASE WHERE 
\begin_inset Formula $t=\frac{1}{20}$
\end_inset

 GOOD? ————————–
\end_layout

\begin_layout Section*
c)
\end_layout

\begin_layout Standard
The value 
\begin_inset Formula $10$
\end_inset

, as this creates a very large gradient on the 
\begin_inset Formula $x$
\end_inset

 coordinate which requires a small step size in order to converge.
\end_layout

\begin_layout Section*
d)
\end_layout

\begin_layout Paragraph*

\series medium
As we saw with the series:
\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{1}^{k}=\left(1-20t\right)^{k}\left(x_{1}^{0}-1\right)+1
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
\begin_inset Formula 
\[
x_{2}^{k}=\left(1-\frac{t}{5}\right)^{k}\left(x_{2}^{0}+1\right)-1
\]

\end_inset


\end_layout

\begin_layout Paragraph*

\series medium
In general, the 
\begin_inset Formula $y$
\end_inset

 coordinate takes the longest to converge, as for almost all 
\begin_inset Formula $t<\frac{1}{10}$
\end_inset

 we have 
\begin_inset Formula $\left|1-20t\right|<\left|1-\frac{t}{5}\right|$
\end_inset

, and therefore 
\begin_inset Formula $\left(1-20t\right)^{k}$
\end_inset

 converges faster than 
\begin_inset Formula $\left(1-\frac{t}{5}\right)^{k}$
\end_inset

.
\end_layout

\end_body
\end_document
